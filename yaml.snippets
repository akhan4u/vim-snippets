snippet pod "Pod" !b
---
apiVersion: v1
kind: Pod
metadata:
  name: ${1:nginx}
  namespace: ${2:default}
  labels:
    app: $1
spec:
  containers:
    - name: $1
      image: ${3:nginx:latest}
      ports:
        - containerPort: 80
      volumeMounts:
        - name: workdir
          mountPath: /usr/share/nginx/html
      resources:
        limits:
          memory: '1Gi'
          cpu: '800m'
        requests:
          memory: '700Mi'
          cpu: '400m'
  # These containers are run during pod initialization
  initContainers:
    - name: install
      image: busybox
      command:
        - wget
        - '-O'
        - '/work-dir/index.html'
        - http://kubernetes.io
      volumeMounts:
        - name: workdir
          mountPath: '/work-dir'
  dnsPolicy: Default
  volumes:
    - name: workdir
      emptyDir: {}
endsnippet

snippet limits "Configure Default/MIN/MAX CPU & Memory Requests & Limits for a Namespace" !b
---
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-mem-limit-range
spec:
  limits:
  # The default section sets the default limits for a container in a pod.
    - default:
        cpu: 600m
        memory: 100Mi
  # The defaultRequest section sets the default requests for a container in a pod.
      defaultRequest:
        cpu: 100m
        memory: 50Mi
  # The max section will set up the maximum limits that a container in a pod can set.
      max:
        cpu: 1000m
        memory: 200Mi
  # The min section will set up the minimum requests that a container in a pod can set.
      min:
        cpu: 10m
        memory: 10Mi
      type: Container
endsnippet

snippet limits "Configure Default Memory Requests and Limits for a Namespace" !b
# When you add a LimitRange:

# If any Pod in that namespace that includes a container does not specify its own MEMORY limit, the control plane applies default MEMORY limit to that container,
# and the Pod can be allowed to run in a namespace that is restricted by a MEMORY ResourceQuota.

---
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
    - default:
        memory: 512Mi
      defaultRequest:
        memory: 256Mi
      type: Container
endsnippet

snippet limits "Configure Default CPU Requests and Limits for a Namespace" !b
# When you add a LimitRange:

# If any Pod in that namespace that includes a container does not specify its own CPU limit, the control plane applies the default CPU limit to that container,
# and the Pod can be allowed to run in a namespace that is restricted by a CPU ResourceQuota.

---
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-limit-range
spec:
  limits:
    - default:
        cpu: 1
      defaultRequest:
        cpu: 0.5
      type: Container
endsnippet

snippet rc "Replication Controller" !b
# WARNING, use Deployments -- ReplicationController is being replaced.
apiVersion: v1
kind: ReplicationController
metadata:
	name: ${1:some-controller}
	namespace: ${2:default}
spec:
	replicas: 1
	template:
		metadata:
			labels:
				app: $1
				tier: $3
		spec:
			containers:
			- name: ${4:name}
				image: ${5:nginx}
				imagePullPolicy: Always
				resources:
					requests:
						cpu: 100m
						memory: 200Mi
				ports:
				- containerPort: 8080
endsnippet

snippet dep "Deployment" !bm
apiVersion: apps/v1
kind: Deployment
metadata:
	name: ${1:some-controller}
	namespace: ${2:default}
spec:
	replicas: 1
	selector:
		matchLabels:
			$3
	template:
		metadata:
			labels:
				${3:app: $1}
		spec:
			containers:
			- name: ${4:name}
				image: ${5:nginx}
				imagePullPolicy: Always
				resources:
					limits:
						cpu: 800m
						memory: 800Mi
					requests:
						cpu: 100m
						memory: 200Mi
				ports:
				- containerPort: 8080
endsnippet

snippet svc "Service ClusterIP (default)" !b
apiVersion: v1
kind: Service
metadata:
	name: ${1:frontend}
	namespace: ${2:default}
	labels:
		app: ${3:someApp}
		tier: ${4:frontend}
spec:
	ports:
	- port: ${5:80}
	selector:
		app: $3
		tier: $4
endsnippet

snippet svc "Service NodePort" !b
apiVersion: v1
kind: Service
metadata:
  name: ${1:frontend}
  namespace: ${2:default}
  labels:
    app: ${3:someApp}
    tier: ${4:frontend}
spec:
  type: NodePort
  selector:
    app.kubernetes.io/name: MyApp
    app: $3
    tier: $4
  ports:
      # By default and for convenience, the 'targetPort' is set to the same value as the 'port' field.
    - port: 80
      targetPort: 80
      # Optional field
      # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767)
      nodePort: 30007
endsnippet

snippet svc "AWS LoadBalancer" !b
apiVersion: v1
kind: Service
metadata:
  name: ${1:frontend}
  namespace: ${2:default}
  annotations:
    # More details on Annotations here: https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.4/guide/service/annotations/#annotations
    # Set LoadBalancer Scheme
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"  # Accepted values: 'internet-facing', 'internal'
    # Set LoadBalancer Type
    service.beta.kubernetes.io/aws-load-balancer-type: "classic" # Accepted values: 'classic', 'nlb', 'alb'
    # Set LoadBalancer Name
    service.beta.kubernetes.io/aws-load-balancer-name: "argo-events.elb"
    # Whitelist below IP CIDR's
    service.beta.kubernetes.io/load-balancer-source-ranges: "192.30.252.0/22, 185.199.108.0/22, 140.82.112.0/20, 143.55.64.0/20"
    # Add an ACM Certificate on LB
    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: 'arn:aws:acm:us-east-1:998801114546:certificate/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx'
    # Resource Tagging
    service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags: "purpose=argo-poc"
  labels:
    app: ${3:someApp}
    tier: ${4:frontend}
spec:
  type: LoadBalancer
  selector:
    app: $3
    tier: $4
  ports:
    - port: 80
      targetPort: 8080
      name: http
    - port: 443
      targetPort: 8080
      name: https
endsnippet

snippet svcns "Access Service in Another Namespace" !b
kind: Service
apiVersion: v1
metadata:
  name: service-y
  namespace: namespace-a
spec:
  type: ExternalName
  externalName: service-y.namespace-b.svc.cluster.local
  ports:
  - port: 80

# Use : <service name> (Use if in same namespace)
# Use : <service.name>.<namespace name> (Use if across namespace)
# Use : <service.name>.<namespace name>.svc.cluster.local (FQDN)
# More details: https://stackoverflow.com/questions/37221483/service-located-in-another-namespace
endsnippet

snippet depsvc "Deployment and service" !b
apiVersion: apps/v1
kind: Deployment
metadata:
	name: ${1:some-controller}
	namespace: ${2:default}
spec:
	replicas: 1
	selector:
		matchLabels:
			$3
	template:
		metadata:
			labels:
				${3:app: $1}
		spec:
			containers:
			- name: ${4:name}
				image: ${5:nginx}
				imagePullPolicy: Always
				resources:
					limits:
						cpu: 800m
						memory: 800Mi
					requests:
						cpu: 100m
						memory: 200Mi
				ports:
				- containerPort: ${6:8080}
---
apiVersion: v1
kind: Service
metadata:
	name: $1
	namespace: $2
spec:
	ports:
	- port: ${7:80}
		targetPort: $6
	selector:
		$3
endsnippet

snippet depsvcing "Deployment, service, and ingress" !b
apiVersion: apps/v1
kind: Deployment
metadata:
	name: ${1:some-controller}
	namespace: ${2:default}
spec:
	replicas: 1
	selector:
		matchLabels:
			$3
	template:
		metadata:
			labels:
				${3:app: $1}
		spec:
			containers:
			- name: ${4:name}
				image: ${5:nginx}
				imagePullPolicy: Always
				resources:
					limits:
						cpu: 800m
						memory: 800Mi
					requests:
						cpu: 100m
						memory: 200Mi
				ports:
				- containerPort: ${6:8080}
---
apiVersion: v1
kind: Service
metadata:
	name: $1
	namespace: $2
spec:
	ports:
	- port: ${7:80}
		targetPort: $6
	selector:
		$3
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
	name: $1
	namespace: $2
spec:
	${10:tls:
	- secretName: ${9:$8.tls}
		hosts:
		- $8
	}rules:
	- host: ${8:host}
		http:
			paths:
			- path: ${11:/}
				backend:
					serviceName: $1
					servicePort: $7
endsnippet

snippet pv "PersistentVolume" !b
apiVersion: v1
kind: PersistentVolume
metadata:
	name: ${1:name}
	labels:
		app: ${2:app}
		tier: ${3:tier}
spec:
	capacity:
		storage: ${4:20Gi}
	accessModes:
		- ${5:ReadWriteMany}
	nfs:
		server: ${6:NameOrIP}
		path: ${7:"/share/path/on/server"}
endsnippet

snippet pvc "PersistentVolumeClaim" !b
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
	name: ${1:name}
	labels:
		# insert any desired labels to identify your claim
		app: ${2:app}
		tier: ${3:tier}
spec:
	${4:storageClassName: ${5:standard}}
    # accessModes:
    # • ReadWriteOnce (RWO) - Volume allows read/write by only one node at the same time.
    # • ReadWriteMany (RWX) - Volume allows read/write by multiple nodes at the same time.
    # • ReadOnlyMany  (ROX) - Volume allows read-only mode by many nodes at the same time.
	accessModes:
		- ${6:ReadWriteOnce}
	resources:
		requests:
			# The amount of the volume's storage to request
			storage: ${7:20Gi}
endsnippet

snippet ing "Ingress" !b
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
	name: ${1:name}
	namespace: ${2:default}
spec:
	${5:tls:
	- secretName: ${4:$3.tls}
		hosts:
		- $3
	}rules:
	- host: ${3:host.tld}
		http:
			paths:
			- path: ${7:/}
				backend:
					serviceName: ${8:service}
					servicePort: ${9:portNumberOrName}
endsnippet

snippet ns "Namespace" !b
apiVersion: v1
kind: Namespace
metadata:
	name: ${1:name}
endsnippet

snippet sa "ServiceAccount" !b
apiVersion: v1
kind: ServiceAccount
metadata:
	name: ${1:name}
endsnippet

snippet ingtls "Ingress TLS section" !b
tls:
- secretName: ${2:$1.tls}
	hosts:
	- ${1:host}
endsnippet

snippet cfg "ConfigMap" !b
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${1:name}
data:
  # Configuration values can be set as key-value properties
  ${3:key}: ${4:value}
  database: mongodb
  database_uri: mongodb://localhost:27017

  # Or set as complete file contents (even JSON!)
  keys: |
    image.public.key=771
    rsa.public.key=42
endsnippet

snippet cfgr "ConfigMap Reference" !b
apiVersion: v1
kind: Pod
metadata:
  name: your-pod
spec:
  containers:
    - name: env-var-configmap
      image: nginx:1.7.9
      envFrom:
        - configMapRef:
            name: example-configmap
endsnippet

snippet sec "Secret" !b
apiVersion: v1
kind: Secret
metadata:
  name: ${1:secret-name}
type: ${2:Opaque}
data:
  ${3:key}: ${4:value}
endsnippet

snippet env "Environment template" !b
- name: ${1:VAR_NAME}
  value: ${2:value}
endsnippet

snippet pvol "Pod Volume Object"
- name: ${1:name}
	${2:source}:
		name:
endsnippet

snippet job "Kubernetes Job" !b
apiVersion: batch/v1
kind: Job
metadata:
	name: ${1:jobname}
	labels:
		${2:sometag: somevalue}
spec:
	template:
		metadata:
			name: $1
		spec:
			containers:
			- name: ${3:containerName}
				image: ${4: image}
				imagePullPolicy: Always
				command:
				- ${5:"override"
				- "--the"
				- "entrypoint"}
			restartPolicy: OnFailure|Never
endsnippet

snippet cron "Kubernetes Cronjob" !b
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ${1:name}
spec:
  # Specifies how to treat concurrent executions of a Job. Valid values are:
  # - "Allow" allows CronJobs to run concurrently
  # - "Forbid" forbids concurrent runs, skipping next run if previous hasn't finished yet
  # - "Replace" cancels currently running job and replaces it with a new one
  concurrencyPolicy: Allow
  # Optional deadline in seconds for starting the job if it misses scheduled time for any reason.
  # Missed jobs executions will be counted as failed ones
  startingDeadlineSeconds: 30
  # The number of failed finished jobs to retain. Value must be non-negative integer. Defaults to 1
  failedJobsHistoryLimit: 1
  # The number of successful finished jobs to retain. Value must be non-negative integer. Defaults to 3
  successfulJobsHistoryLimit: 3
  schedule: '${2:*/5} * * * *'
  jobTemplate:
    metadata:
      name: $1
    spec:
      # Specifies the number of retries before marking this job failed. Defaults to 6
      backoffLimit: 3
      template:
        spec:
          containers:
          - name: $1
            image: ${3:busybox}
            imagePullPolicy: Always
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          # Restart policy for all containers within the pod. One of Always, OnFailure, Never
          restartPolicy: OnFailure
endsnippet

snippet skr "SecretKeyRef"
valueFrom:
	secretKeyRef:
		name: ${1:secret-name}
		key: ${2:key-name}
endsnippet

snippet cert "cert-manager certificate" !b
apiVersion: certmanager.k8s.io/v1alpha1
kind: Certificate
metadata:
	name: ${1:name}
	namespace: ${2:namespace}
spec:
	secretName: ${4:$3.tls}
	dnsNames:
	- ${3:some.domain.com}
	acme:
		config:
		- dns01:
				provider: ${4:prod}
			domains: [ $3 ]
	issuerRef:
		name: ${5:letsencrypt}
		kind: ClusterIssuer
endsnippet


snippet netp "NetworkPolicy" !b
kind: NetworkPolicy
apiVersion: extensions/v1beta1
metadata:
	namespace: ${1:default}
	name: ${2:policyname}
	spec:
	${4:podSelector:
			matchLabels:
				${3:{}}
}	ingress:
			- {}
endsnippet

snippet probe "Liveness/Readiness Probes" !b
livenessProbe: &probe
	initialDelaySeconds: ${1:10}
	httpGet:
		port: ${2:8080}
		path: ${3:/}
readinessProbe: *probe $0
endsnippet

snippet ss "StatefulSet" !b
apiVersion: v1
kind: Service
metadata:
	name: ${1:myservice}
spec:
	ports:
	- port: $5
		name: $6
	clusterIP: None
	selector:
		$2
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
	name: ${1:mystatefulset}
spec:
	selector:
		matchLabels:
			$2
	serviceName: "nginx"
	replicas: 3 # by default is 1
	template:
		metadata:
			labels:
				${2:app: $1}
		spec:
			# terminationGracePeriodSeconds: 10
			containers:
			- name: ${3:$1}
				image: ${4:$1}
				ports:
				- containerPort: ${5:80}
					name: ${6:web}
				volumeMounts:
				- name: ${7:volume}
					mountPath: ${8:/var/lib/mydata}
	volumeClaimTemplates:
	- metadata:
			name: $7
		spec:
			accessModes: [ "ReadWriteOnce" ]
			storageClassName: "${9:standard}"
			resources:
				requests:
					storage: ${10:1G}
endsnippet

snippet res "Resources" !b
resources:
	requests:
		cpu: ${1:100m}
		memory: ${2:200Mi}
	${5:limits:
		cpu: ${3:$1}
		memory: ${4:$2}}$0
endsnippet

snippet init "Init Container" !b
initContainers:
- name: ${1:myinit}
	image: ${2:busybox}
	command: [${3:rm, -rf,  $5/lost+found}]
	${6:volumeMounts:
	- name: ${4:data}
		mountPath: ${5:/data}}$0
endsnippet

snippet strat "Deployment Strategy" !b
strategy:
	type: ${1:RollingUpdate|Recreate}
	rollingUpdate:
		maxSurge: ${2:1}
		maxUnavailable: ${3:1}$0
endsnippet

snippet atls "tls-acme annotations" !b
annotations:
	kubernetes.io/tls-acme: "true"
endsnippet

snippet vtls "tls-vault annotations" !b
annotations:
	kubernetes.io/tls-vault: "true"
endsnippet

snippet cmtls "cert-manager tls annotations" !b
${2:annotations:
	}certmanager.k8s.io/cluster-issuer: ${1:lets-encrypt}
endsnippet

snippet edns "external dns" !b
annotations:
	external-dns.alpha.kubernetes.io/hostname: ${1:myname.mydomain.com}
endsnippet

snippet role "Role" !b
kind: ${1:Cluster}Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
	${2:namespace: ${3:default}
	}name: ${4:configmap-updater}
rules:
- apiGroups: ["${5:}"]
	resources: ["${6:configmaps}"]
	resourceNames: ["${7:my-configmap}"]
	verbs: [${8:"update", "get"}]
endsnippet

snippet rb "RoleBinding" !b
# This role binding allows "jane" to read pods in the "default" namespace.
kind: ${1:Cluster}RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
	name: ${2:read-pods}
	${3:namespace: ${4:pods}
}subjects:
- kind: ${5:User|ServiceAccount|Group}
	name: ${6:jane} # Name is case sensitive
	apiGroup: rbac.authorization.k8s.io
roleRef:
	kind: ${7:Cluster}Role #this must be Role or ClusterRole
	name: ${8:pod-reader} # this must match the name of the Role or ClusterRole you wish to bind to
	apiGroup: rbac.authorization.k8s.io
endsnippet

snippet rbac "Role and Binding" !b
kind: ${1:Cluster}Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
	${2:namespace: ${3:default}
	}name: ${4:configmap-updater}
rules:
- apiGroups: ["${5:}"]
	resources: ["${6:configmaps}"]
	resourceNames: ["${7:my-configmap}"]
	verbs: [${8:"update", "get"}]
---
# This role binding allows "jane" to read pods in the "default" namespace.
kind: ${9:Cluster}RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
	name: $4
	$2
subjects:
- kind: ${10:User|ServiceAccount|Group}
	name: ${11:jane} # Name is case sensitive
	apiGroup: rbac.authorization.k8s.io
roleRef:
	kind: $1Role #this must be Role or ClusterRole
	name: $4 # this must match the name of the Role or ClusterRole you wish to bind to
	apiGroup: rbac.authorization.k8s.io
endsnippet

snippet hpa "HorizontalPodAutoscaler (apiVersion: autoscaling/v1)" !b
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
	name: ${5:$1}
spec:
	scaleTargetRef:
		apiVersion: apps/v1
		kind: Deployment
		name: ${1:mydeployment}
	minReplicas: ${2:1}
	maxReplicas: ${3:5}
	targetCPUUtilizationPercentage: ${4:70}
endsnippet

snippet pvolm "Volume Mount and spec" !b
	volumeMounts:
	- name: ${1:volume}
		mountPath: ${2:/etc/mount/path}
		${3:subPath: ${4: key}}
volumes:
- name: $1
	${5:configMap}:
		${6:name}: ${7:someName}
endsnippet

snippet volm "Volume Mount" !b
- name: ${1:volume}
	mountPath: ${2:/etc/mount/path}
	${3:subPath: ${4: key}}
$0
endsnippet

snippet prom "Prometheus annotations" !b
annotations:
	prometheus.io/scrape: "true"
	prometheus.io/endpoint: "${1:/metrics}"
	prometheus.io/port: "${2:8080}"
endsnippet

snippet aff "Affinitiy/Anti-Affinity" !b
pod${1:Anti}Affinity:
	${2:preferred|required}DuringSchedulingIgnoredDuringExecution:
	- weight: 100
		podAffinityTerm:
			labelSelector:
				matchExpressions:
				- key: ${3:app}
					operator: In
					values:
					- ${4:appname}
			topologyKey: ${5:kubernetes.io/hostname}
endsnippet

snippet hpa "Horizontal Pod Autoscaler (apiVersion: autoscaling/v2beta1)" !b
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: ${1:hpa-name}
  namespace: ${2:default}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ${3:deployment-name}
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 10
  - type: Resource
    resource:
      name: memory
      targetAverageValue: 1000Mi
endsnippet

snippet hpa "Horizontal Pod Autoscaler (apiVersion: autoscaling/v2)" !b
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ${1:hpa-name}
  namespace: ${2:default}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ${3:deployment-name}
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 250
  - type: Pods
    pods:
      metric:
        name: packets-per-second
      target:
        type: AverageValue
        averageValue: 1k
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        name: main-route
      target:
        type: Value
        value: 10k
endsnippet

snippet cf_init "Blank CloudFormation Template" !b
AWSTemplateFormatVersion: "2010-09-09"
Description: ${1: Welcome to CFn template!!}
Parameters:
  Parameter1:
    Type: String
    Description: Enter Your Description
    Default: ${2}
    AllowedValues:
      - $2
Resources:
Outputs:
  Output1:
    Description: "Enter Your Description"
    Value: "${3:Enter value to export}"
    Export:
      Name: "${4:Enter your export name}"
endsnippet

snippet cf_param "Define CloudFormation Parameter" !b
Parameter1:
  Type: String
  Description: Enter Your Description
  Default: ${1}
  AllowedValues:
    - $1
endsnippet

snippet cf_output "Define CloudFormation Output" !b
Output1:
  Description: "Enter Your Description"
  Value: "${1:Enter value to export}"
  Export:
    Name: "${2:Enter your export name}"
endsnippet

snippet cf_tags "CloudFormation Resource Tags" !b
Tags:
  - Key: ${1}
    Value: ${2}
endsnippet

snippet ghactions "Github Actions file (Basic)" !b
name: Sample Github Actions File

on:
  push:
    branches:
      - main

  pull_request:
    types:
      - opened

jobs:
  build: # this can be any name you choose
    name: build application
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo code
        uses: actions/checkout@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      - name: List repo files
        run: |
          ls -la
          cat README.md
      - name: Install cowsay
        run: |
          pip install cowsay
          cowsay 'hello'
endsnippet

snippet ghactions "Github Actions file (NodeJS)" !b
name: Build NodeJS Project

on: [push, pull_request]

jobs:
  build: # this can be any name you choose
  # Specify the operating system for the job
  runs-on: ubuntu-latest
  steps:
    # Checkout the repository so that workflow can access the code
    - name: Checkout code
      uses: actions/checkout@v2

    # Set up Node.js environment
    - name: Set up Node.js
      uses: actions/setup-node@v2
      with:
        node-version: '14'

    # Install dependencies using npm
    - name: Install Dependencies
      run: npm ci

    # Build the project
    - name: Build
      run: npm build

    # Run unit tests
    - name: Run Tests
      run: npm test

    # Publish code coverage report using codecov
    - name: Publish Code Coverage
      uses: codecov/codecov-action@v2

    # Deploy the application to a server
    - name: Deploy to Server
      run: ssh user@server 'cd /path/to/project && git pull'
endsnippet

snippet ghactions "Github Actions file (Python)" !b
name: Python package

on: [push]

jobs:
  build: # this can be any name you choose

    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9", "3.10", "3.11"]

    steps:
      - uses: actions/checkout@v3
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff pytest
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      - name: Lint with ruff
        run: |
          # stop the build if there are Python syntax errors or undefined names
          ruff --format=github --select=E9,F63,F7,F82 --target-version=py37 .
          # default set of ruff rules with GitHub Annotations
          ruff --format=github --target-version=py37 .
      - name: Test with pytest
        run: |
          pytest
endsnippet

snippet circleci "CircleCI Config file (Basic)" !b
# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/configuration-reference
version: 2.1

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/configuration-reference/#jobs
jobs:
  say-hello:
    # Specify the execution environment. You can specify an image from Docker Hub or use one of our convenience images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/configuration-reference/#executor-job
    docker:
      - image: cimg/base:stable
    # Add steps to the job
    # See: https://circleci.com/docs/configuration-reference/#steps
    steps:
      - checkout
      - run:
          name: "Say hello"
          command: "echo Hello, World!"

# Orchestrate jobs using workflows
# See: https://circleci.com/docs/configuration-reference/#workflows
workflows:
  say-hello-workflow:
    jobs:
      - say-hello
endsnippet

snippet circleci "CircleCI Config file (Concurrent Execution)" !b
version: 2.1

# Define the jobs we want to run for this project
jobs:
  build:
    docker:
      - image: cimg/base:2023.03
    steps:
      - checkout
      - run: echo "this is the build job"
  test:
    docker:
      - image: cimg/base:2023.03
    steps:
      - checkout
      - run: echo "this is the test job"

# Orchestrate our job run sequence
workflows:
  build_and_test:
    jobs:
      - build
      - test
endsnippet

snippet circleci "CircleCI Config file (Sequential Execution)" !b
version: 2.1

# Define the jobs we want to run for this project
jobs:
  build:
    docker:
      - image: cimg/base:2023.03
    steps:
      - checkout
      - run: echo "this is the build job"
  test:
    docker:
      - image: cimg/base:2023.03
    steps:
      - checkout
      - run: echo "this is the test job"

# Orchestrate our job run sequence
workflows:
  build_and_test:
    jobs:
      - build
      - test:
          requires:
            - build
endsnippet

snippet circleci "CircleCI Config file (Approval Workflow)" !b
version: 2.1

# Define the jobs we want to run for this project
jobs:
  build:
    docker:
      - image: cimg/base:2023.03
    steps:
      - checkout
      - run: echo "this is the build job"
  test:
    docker:
      - image: cimg/base:2023.03
    steps:
      - checkout
      - run: echo "this is the test job"
  deploy:
    docker:
      - image: cimg/base:2023.03
    steps:
      - checkout
      - run: echo "this is the deploy job"

# Orchestrate our job run sequence
workflows:
  build_and_test:
    jobs:
      - build
      - test:
          requires:
            - build
      - hold:
          type: approval
          requires:
            - build
            - test
      - deploy:
          requires:
            - hold
endsnippet

snippet gitlab "Gitlab Config file (BASH)" !b
# You can copy and paste this template into a new `.gitlab-ci.yml` file.
# You should not add this template to an existing `.gitlab-ci.yml` file by using the `include:` keyword.
#
# A full list of available templates can be found here:
# https://docs.gitlab.com/ee/ci/examples/#cicd-templates
# To contribute improvements to CI/CD templates, please follow the Development guide at:
# https://docs.gitlab.com/ee/development/cicd/templates.html
# This specific template is located at:
# https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Bash.gitlab-ci.yml

# See https://docs.gitlab.com/ee/ci/yaml/index.html for all available options

# you can delete this line if you're not using Docker
image: busybox:latest

before_script:
  - echo "Before script section"
  - echo "For example you might run an update here or install a build dependency"
  - echo "Or perhaps you might print out some debugging details"

after_script:
  - echo "After script section"
  - echo "For example you might do some cleanup here"

build1:
  stage: build
  script:
    - echo "Do your build here"

test1:
  stage: test
  script:
    - echo "Do a test here"
    - echo "For example run a test suite"

test2:
  stage: test
  script:
    - echo "Do another parallel test here"
    - echo "For example run a lint test"

deploy1:
  stage: deploy
  script:
    - echo "Do your deploy here"
  environment: production
endsnippet

snippet ghactions "Github Actions file (Java)" !b
name: Java CI

on: [push]

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          distribution: 'temurin'
      - name: Build with Maven
        run: mvn --batch-mode --update-snapshots package
endsnippet

snippet ghactions "Github Actions file (Manual Approval)" !b
name: Github Actions with Manual Approval

on: [workflow_dispatch, pull_request, push]

jobs:
  build:
    name: build
    runs-on: ubuntu-latest
    steps:
      - name: Build
        run: echo building
  deploy:
    name: deploy
    runs-on: ubuntu-latest
    needs: build
    steps:
      - uses: trstringer/manual-approval@v1
        with:
          secret: ${{ github.TOKEN }}
          approvers: trstringer,acdunnigan
      - name: Deploy to production
        run: echo deploying
endsnippet

snippet ghactions "Github Actions file (Python - Unit Testing)" !b
name: unit test

on:
  push:
    branches:
      - master
      - detection
    paths:
      - '**.py'
      - '.github/workflows/unit-test.yml'
      - 'environment.yml'
  pull_request:
    branches:
      - master
      - detection
    paths:
      - '**.py'
      - '.github/workflows/unit-test.yml'
      - 'environment.yml'

jobs:
  unit-test:
    name: unit test
    runs-on: ubuntu-latest
    container:
      image: continualai/avalanche-test-${{ matrix.python-version }}:latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.7", "3.8", "3.9", "3.10"]
    defaults:
      run:
        shell: bash -l -c "conda run -n avalanche-env --no-capture-output bash {0}"
    steps:
      - uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      - name: python unit test
        id: unittest
        env:
          FAST_TEST: "True"
          USE_GPU: "False"
        run: |
          python -m unittest discover tests &&
          echo "Checking that optional dependencies are not needed" &&
          pip uninstall -y higher ctrl-benchmark torchaudio gym pycocotools lvis &&
          PYTHONPATH=. python examples/eval_plugin.py &&
          echo "Running checkpointing tests..." &&
          bash ./tests/checkpointing/test_checkpointing.sh &&
          echo "Running distributed training tests..." &&
          cd tests &&
          PYTHONPATH=.. python run_dist_tests.py &&
          cd .. &&
          echo "While running unit tests, the following datasets were downloaded:" &&
          ls ~/.avalanche/data
endsnippet

snippet ghactions "Github Actions file (Cron Schedule)" !b
name: Docker Nightly Release

on:
  schedule:
  # Check cron syntax on https://crontab.guru
    - cron: '0 0 * * *'  # everyday at midnight
  push:
    branches:
      - 'master'
    paths:
      - 'docker/nightly/**'
      - '.github/workflows/docker-nightly-release.yml'

jobs:
  docker-nightly-release:
    runs-on: ubuntu-latest
    if: ${{ github.repository == 'ContinualAI/avalanche' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Check date of last commit
        run: |
          let DIFF=(`date +%s -d "1 day ago"`-`git log -1 --pretty=format:%ct`) &&
          echo "date_diff=$DIFF" >> $GITHUB_ENV
      - name: Login to DockerHub
        if: ${{ env.date_diff <= 0 }}  # last commit < 24h ago
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PSW }}
      - name: Log in to the Container registry
        if: ${{ env.date_diff <= 0 }}  # last commit < 24h ago
        uses: docker/login-action@v1
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - name: Build and push
        if: ${{ env.date_diff <= 0 }}  # last commit < 24h ago
        uses: docker/build-push-action@v2
        with:
          context: docker/nightly
          push: true
          tags: |
            ${{ secrets.DOCKERHUB_USERNAME }}/avalanche-nightly:latest
            ghcr.io/continualai/avalanche-nightly:latest
endsnippet

snippet pod "Pod Spec honouring IndexExchange's Admission Webhook Rules" !b
---
apiVersion: v1
kind: Pod
metadata:
  name: index-test
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    supplementalGroups: [0]
  containers:
    - name: index-test
      image: registry.indexexchange.com:5000/python:3.6-alpine
      command:
        - sh
        - -c
        - |
          #!/usr/bin/env bash -e
          python -m http.server 8080 &
          while true ; do sleep 5 && echo "$(date) -> Hello from pod $(hostname)" ; done
      ports:
        - containerPort: 8080
          name: http
          protocol: TCP
      resources:
        limits:
          memory: '600Mi'
          cpu: '500m'
        requests:
          memory: '400Mi'
          cpu: '300m'
      livenessProbe:
        initialDelaySeconds: 5
        periodSeconds: 5
        timeoutSeconds: 1
        successThreshold: 1
        failureThreshold: 1
        httpGet:
          host:
          scheme: HTTP
          path: /
          httpHeaders:
          - name: Host
            value: localhost
          port: 8080
      readinessProbe:
        exec:
          command:
            - cat
            - /etc/os-release
      securityContext:
        readOnlyRootFilesystem: true
endsnippet

snippet pod "Security Hardened Pod manifest" !b
---
# Define the API version for the Pod object
apiVersion: v1
# Specify the kind of Kubernetes object being defined
kind: Pod
# Metadata block for the Pod object
metadata:
  # Name of the Pod object
  name: nginx
  # Namespace where the Pod will be deployed; not default
  namespace: custom
  # Labels assigned to the Pod object
  labels:
    # Label indicating the application name
    app: nginx
# Specification block for the Pod object
spec:
  # Security context for the Pod
  securityContext:
    # Type of seccomp profile to apply
    seccompProfile:
      type: "RuntimeDefault"
  # Containers to be run inside the Pod
  containers:
    - name: nginx
      # Pull policy for the container image
      imagePullPolicy: Always
      # Specific image to use for the container, pinned by digest for enhanced security
      image: index.docker.io/library/nginx@sha256:6af79ae5de407283dcea8b00d5c37ace95441fd58a8b1d2aa1ed93f5511bb18c
      # Ports exposed by the container
      ports:
        - containerPort: 80
      # Volume mounts for the container
      volumeMounts:
        - name: workdir
          mountPath: /usr/share/nginx/html
      # Resource limits and requests for the container
      resources:
        limits:
          memory: '1Gi'
          cpu: '800m'
        requests:
          memory: '700Mi'
          cpu: '400m'
      # Security context for the container
      # NOTE: Field values of container.securityContext take precedence over field values of PodSecurityContext
      securityContext:
        # Run the container as a specific user ID
        runAsUser: 10001
        # Run the container as a specific group ID
        runAsGroup: 10001
        # Prevent the container from gaining root privileges
        runAsNonRoot: true
        # List of supplementary groups to add to the container's group IDs
        supplementalGroups: [10001]
        # Mount the container's filesystem as read-only
        readOnlyRootFilesystem: true
        # Do not grant extended privileges to the container
        privileged: false
        # Disable privilege escalation
        allowPrivilegeEscalation: false
        # Capabilities to drop from the container
        capabilities:
          drop:
            - all
        # Seccomp profile type
        seccompProfile:
          type: "RuntimeDefault"
  # Init containers to run before the main containers
  initContainers:
    - name: install
      # Pull policy for the init container image
      imagePullPolicy: Always
      # Specific image to use for the init container, pinned by digest for enhanced security
      image: index.docker.io/library/busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
      # Command to execute in the init container
      command:
        - wget
        - '-O'
        - '/work-dir/index.html'
        - http://kubernetes.io
      # Volume mounts for the init container
      volumeMounts:
        - name: workdir
          mountPath: '/work-dir'
      # Resource limits and requests for the init container
      resources:
        limits:
          cpu: '300m'
          memory: '500Mi'
        requests:
          cpu: '150m'
          memory: '200Mi'
      # Security context for the init container
      securityContext:
        # Run the init container as a specific user ID
        runAsUser: 10001
        # Run the init container as a specific group ID
        runAsGroup: 10001
        # Prevent the init container from gaining root privileges
        runAsNonRoot: true
        # List of supplementary groups to add to the init container's group IDs
        supplementalGroups: [10001]
        # Mount the init container's filesystem as read-only
        readOnlyRootFilesystem: true
        # Do not grant extended privileges to the init container
        privileged: false
        # Disable privilege escalation for the init container
        allowPrivilegeEscalation: false
        # Capabilities to drop from the init container
        capabilities:
          drop:
            - all
        # Seccomp profile type for the init container
        seccompProfile:
          type: "RuntimeDefault"
  # DNS policy for the Pod
  dnsPolicy: Default
  # Volumes to be mounted into the Pod
  volumes:
    - name: workdir
      emptyDir: {}
endsnippet
